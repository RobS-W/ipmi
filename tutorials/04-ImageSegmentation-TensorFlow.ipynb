{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Convolutional Neural Networks - Medical Image Segmentation (TensorFlow)\n",
    "\n",
    "This tutorial is solving a real-world problem in segmenting anatomical organs in 3D medical images, an argubly most successful area deep-learning has been applied to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Image and Label Data\n",
    "\n",
    "The images and labels (segmentations) in [PROMISE12][promise12] are used here. Download a copy of resampeld data by cloning the following repository:\n",
    "\n",
    "\n",
    "[promise12]: https://promise12.grand-challenge.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/YipengHu/promise12.git\n",
    "\n",
    "path_to_data = \"./promise12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *path_to_data* shoud contain all the data needed. If _git_ is not available as a system command (e.g. on Windows), the same data can also be downloaded here:\n",
    "\n",
    "[Download Data][data_link]. \n",
    "\n",
    "In this case, the *path_to_data* needs to be specified to where the data are unzipped. For those who are interested, the script [*script_promise12*][script_promise12.py] has the code that resampled the original data. \n",
    "\n",
    "\n",
    "[data_link]: https://github.com/YipengHu/promise12/archive/data.zip\n",
    "[script_promise12.py]: ./data/script_promise12.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check a few images and labels in the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# load a training image-label pair\n",
    "idx = 49\n",
    "image = np.load(os.path.join(path_to_data, \"image_train%02d.npy\" % idx))\n",
    "label = np.load(os.path.join(path_to_data, \"label_train%02d.npy\" % idx))\n",
    "size_data = list(image.shape)\n",
    "\n",
    "# plot the pair\n",
    "idx_slice = 16\n",
    "plt.figure()\n",
    "plt.imshow(image[idx_slice,:,:], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(label[idx_slice,:,:], cmap='gray')\n",
    "\n",
    "# and check to see if the mask is actually segmenting the ROI\n",
    "plt.figure()\n",
    "plt.imshow(image[idx_slice,:,:] * label[idx_slice,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data feeding\n",
    "For convinience, a very simple class for data feeding is loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple npy image reading class\n",
    "class DataReader:\n",
    "\n",
    "    def __init__(self, folder_name):\n",
    "        self.folder_name = folder_name\n",
    "\n",
    "    def load_images_train(self, indices_mb):\n",
    "        return self.load_npy_files([\"image_train%02d.npy\" % idx for idx in indices_mb])\n",
    "\n",
    "    def load_images_test(self, indices_mb):\n",
    "        return self.load_npy_files([\"image_test%02d.npy\" % idx for idx in indices_mb])\n",
    "\n",
    "    def load_labels_train(self, indices_mb):\n",
    "        return self.load_npy_files([\"label_train%02d.npy\" % idx for idx in indices_mb])\n",
    "\n",
    "    def load_npy_files(self, file_names):\n",
    "        images = [np.float32(np.load(os.path.join(self.folder_name, fn))) for fn in file_names]\n",
    "        return np.expand_dims(np.stack(images, axis=0), axis=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Computation Graph for a Fully Convolutional Neural Network\n",
    "The following script is not optimised for performace or best coding practice. This illustrates a basic working workflow to do image segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Placeholders\n",
    "Again, this is a special feature in TensorFlow to facilitate runtime data feeding. This will become clear later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# --- First define placeholders with fixed sizes\n",
    "size_minibatch = 4  # number of images as one input minibatch\n",
    "# only the gray-scale intensity values as one-channel feature, hence [1]:\n",
    "ph_image = tf.placeholder(tf.float32, [size_minibatch]+size_data+[1])\n",
    "ph_label = tf.placeholder(tf.float32, [size_minibatch]+size_data+[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Encoder-decoder network\n",
    "This is a simplified imlementatin of an encoder-decoder network for image segmentation, similar to [U-Net][unet_paper].\n",
    "\n",
    "[unet_paper]: https://arxiv.org/abs/1505.04597\n",
    "\n",
    "We first halve image size so this can be reasonably tested, e.g. on a CPU. and usually, there is a data pre-processing (augmentation) layer in this place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = ph_image[:, ::2, ::2, ::2, :]\n",
    "input_label = ph_label[:, ::2, ::2, ::2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 - declare variables for storing convolution kernel \"weights\" to optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_conv = [3, 3, 3]  # convolution kernel size\n",
    "nc1 = 8  # number of feature maps after the convolution layer, i.e. channels\n",
    "W1 = tf.get_variable(\"W1\", shape=k_conv+[1, nc1], initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 - include the following in a \"convolution layer\":\n",
    "- (a) 3d convolution with padded feature maps (for convenience in working out the sizes at different resolution levels)\n",
    "- (b) batch normalisation, and\n",
    "- (c) nonlinear activation (relu in this case)\n",
    "- (d) polling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strides_one = [1, 1, 1, 1, 1]  # stride of the sliding window used in convolution\n",
    "layer1c = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(input_image, W1, strides_one, padding=\"SAME\")))\n",
    "k_pool = [1, 2, 2, 2, 1]  # kernel for pooling\n",
    "layer1 = tf.nn.max_pool3d(layer1c, k_pool, strides_one, \"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3 - add a down-sampling convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc2 = nc1*2  # double the number of feature maps\n",
    "W2 = tf.get_variable(\"W2\", shape=k_conv+[nc1, nc2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer2c = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer1, W2, strides_one, \"SAME\")))\n",
    "# down-sample via pooling layer\n",
    "strides_two = [1, 2, 2, 2, 1]  # stride used for down-sampling and up-sampling\n",
    "layer2 = tf.nn.max_pool3d(layer2c, k_pool, strides_two, \"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step4 - add two more of these down-sampling blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc3 = nc2*2\n",
    "W3 = tf.get_variable(\"W3\", shape=k_conv+[nc2, nc3], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer3c = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer2, W3, strides_one, \"SAME\")))\n",
    "layer3 = tf.nn.max_pool3d(layer3c, k_pool, strides_two, \"SAME\")\n",
    "\n",
    "nc4 = nc3*2\n",
    "W4 = tf.get_variable(\"W4\", shape=k_conv+[nc3, nc4], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer4c = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer3, W4, strides_one, \"SAME\")))\n",
    "layer4 = tf.nn.max_pool3d(layer4c, k_pool, strides_two, \"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step5 - add a convolution layer without sampling/pooling at the end of down-sampling blocks (i.e. the \"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc5 = nc4*2\n",
    "W5 = tf.get_variable(\"W5\", shape=k_conv+[nc4, nc5], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer5 = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer4, W5, strides_one, \"SAME\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step6 - add an up-sampling block (starting the \"decoder\"), with\n",
    "- (a) the number of feature maps are halved;\n",
    "- (b) use transpose convolution for up-sampling;\n",
    "- (c) make sure the output size is the same as that of layer4c so they can be added (or concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4d = tf.get_variable(\"W4d\", shape=k_conv+[nc4, nc5], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer4d = tf.nn.conv3d_transpose(layer5, W4d, output_shape=layer4c.get_shape(), strides=strides_two, padding=\"SAME\")\n",
    "# (d) add a skip layer (shortcut connection) to the encoder using summation\n",
    "# (e) then add another convolution, batch normalisation and nonlinear activation\n",
    "W4dc = tf.get_variable(\"W4dc\", shape=k_conv+[nc4, nc4], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer4dc = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer4d+layer4c, W4dc, strides_one, \"SAME\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step7 - # add another two of these up-sampling blocks\n",
    "- the final layer should match the original input image size, in order to represent binary segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3d = tf.get_variable(\"W3d\", shape=k_conv+[nc3, nc4], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer3d = tf.nn.conv3d_transpose(layer4dc, W3d, layer3c.get_shape(), strides_two, \"SAME\")\n",
    "W3dc = tf.get_variable(\"W3dc\", shape=k_conv+[nc3, nc3], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer3dc = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer3d+layer3c, W3dc, strides_one, \"SAME\")))\n",
    "\n",
    "W2d = tf.get_variable(\"W2d\", shape=k_conv+[nc2, nc3], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer2d = tf.nn.conv3d_transpose(layer3dc, W2d, layer2c.get_shape(), strides_two, \"SAME\")\n",
    "W2dc = tf.get_variable(\"W2dc\", shape=k_conv+[nc2, nc2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer2dc = tf.nn.relu(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer2d+layer2c, W2dc, strides_one, \"SAME\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step8 - add a \"read-out\" layer with a sigmoid activation\n",
    "- this is to represent the class probabilities;\n",
    "- segmentation can be represented by two classes, forground class (prostate gland) and background class;\n",
    "- or, by just one foreground class, commonly used for many loss functions other than cross entropy;\n",
    "- check if output size is expected: *print(layer1d)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use single channel for soft Dice loss\n",
    "W1d = tf.get_variable(\"W_out\", shape=k_conv+[nc2, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer1d = tf.sigmoid(tf.contrib.layers.batch_norm(tf.nn.conv3d(layer2dc, W1d, strides_one, \"SAME\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Loss for image segmentation\n",
    "Cross-entropy can be used to treat segmentation as a voxel classification problem. Probabilitic (soft) Dice is also widely used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss based on Dice, between predicted segmentation layer_out and ground-truth label\n",
    "dice_numerator = tf.reduce_sum(layer1d*input_label, axis=[1, 2, 3, 4]) * 2\n",
    "# adding a small value for numerical stability\n",
    "dice_denominator = tf.reduce_sum(input_label, axis=[1, 2, 3, 4]) + tf.reduce_sum(layer1d, axis=[1, 2, 3, 4])+1e-6\n",
    "dice = dice_numerator / dice_denominator\n",
    "loss = 1 - tf.reduce_mean(dice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Optimiser\n",
    "Build a training op to specify the numerical optimisation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Set Up the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "total_iter = int(1e5)\n",
    "n = 50  # 50 training image-label pairs\n",
    "num_minibatch = int(n/size_minibatch)  # how many minibatches in each epoch\n",
    "indices_train = [i for i in range(n)]\n",
    "# data reader\n",
    "DataFeeder = DataReader(path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Train with Minibatch Optimisation\n",
    "- Shuffle data every epoch\n",
    "- Feed one minibatch of the data in each iteration\n",
    "- Print training information\n",
    "- Test during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# start the optimisation\n",
    "for step in range(total_iter):\n",
    "\n",
    "    # shuffle data every time start a new set of minibatches\n",
    "    if step in range(0, total_iter, num_minibatch):\n",
    "        random.shuffle(indices_train)\n",
    "\n",
    "    # arrange data indices for a minibatch\n",
    "    minibatch_idx = step % num_minibatch  # minibatch index\n",
    "    indices_mb = indices_train[minibatch_idx*size_minibatch:(minibatch_idx+1)*size_minibatch]\n",
    "    trainFeed = {ph_image: DataFeeder.load_images_train(indices_mb),\n",
    "                 ph_label: DataFeeder.load_labels_train(indices_mb)}\n",
    "\n",
    "    # update the variables\n",
    "    sess.run(train_op, feed_dict=trainFeed)\n",
    "\n",
    "    # print training information\n",
    "    if (step % 10) == 0:\n",
    "        loss_train = sess.run(loss, feed_dict=trainFeed)\n",
    "        print('Step %d: Loss=%f' % (step, loss_train))\n",
    "    if (step % 100) == 0:\n",
    "        dice_train = sess.run(dice, feed_dict=trainFeed)\n",
    "        print('Individual training-Dice:')\n",
    "        print(dice_train)\n",
    "\n",
    "    # --- simple tests during training ---\n",
    "    if (step % 500) == 0:\n",
    "        indices_test = [random.randrange(30) for i in range(size_minibatch)]  # select size_minibatch test data\n",
    "        testFeed = {ph_image: DataFeeder.load_images_test(indices_test)}\n",
    "        layer1d_test = sess.run(layer1d, feed_dict=testFeed)\n",
    "        # save the segmentation\n",
    "        for idx in range(size_minibatch):\n",
    "            np.save(\"./label_test%02d_step%06d.npy\" % (indices_test[idx], step), layer1d_test[idx, ...])\n",
    "        print('Test results saved.')\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Inspect the Segmentation Results on Test Data\n",
    "- A seperate notebook/terminal might be useful to run the following file-reading, avoiding to kill the optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available results\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, more than 500 iterations should produce resaonble results on test data, while several thousand should approach convergence. Since the labels for the test data are not available, the results are assessed qualitatively. Alternatively, one should consider using cross-validation on the training data.\n",
    "\n",
    "As the time of preparing this tutorial, the Challenge still accepts [submissions](https://promise12.grand-challenge.org/evaluation/submissions/create/), although they should be based on original data before resampling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify these to plot the results w.r.t. the images\n",
    "step = 0  \n",
    "idx_case = 29\n",
    "idx_slice = 6\n",
    "\n",
    "image = np.load(os.path.join(path_to_data, \"image_test%02d.npy\" % idx_case))[::2, ::2, ::2]\n",
    "label = np.load(\"label_test%02d_step%06d.npy\" % (idx_case, step))[..., 0]\n",
    "print(label.shape)\n",
    "plt.figure()\n",
    "plt.imshow(image[idx_slice,:,:], cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(label[idx_slice,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If running on Colab, download the saved data:\n",
    "\n",
    "```python\n",
    "from google.colab import files\n",
    "\n",
    "files.download(\"label_test%02d_step%06d.npy\" % (idx_case, step))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
