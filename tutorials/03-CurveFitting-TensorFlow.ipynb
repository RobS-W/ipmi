{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6-He3cXBKfM"
   },
   "source": [
    "# 3 Linear Regression - curve fitting (TensorFlow)\n",
    "Two methods are used to fit a curve:\n",
    "- Direct solution using least-squares method\n",
    "- Iterative optimisation using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pU5v5NAxBKfQ"
   },
   "source": [
    "## 3.1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i2T4JW1SBKfU"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# get ground-truth data from the \"true\" model \n",
    "n = 100 \n",
    "w = [4, 3, 2, 1]\n",
    "x = np.linspace(-1,1,n)[:,np.newaxis]\n",
    "t = np.matmul(np.power(np.reshape(x,[-1,1]), \n",
    "                       np.linspace(len(w)-1,0,len(w))), w)\n",
    "std_noise = 0.2\n",
    "t_observed = np.reshape(\n",
    "    [t[idx]+random.gauss(0,std_noise) for idx in range(n)],\n",
    "    [-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmgdFSrvBKfc"
   },
   "source": [
    "## 3.2 Computation Graph and Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1435,
     "status": "ok",
     "timestamp": 1540321798182,
     "user": {
      "displayName": "Yipeng Hu",
      "photoUrl": "",
      "userId": "18139436242730223489"
     },
     "user_tz": -60
    },
    "id": "8w3xBytsBKff",
    "outputId": "23a13225-f139-47dd-8971-18fd75b203ad"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# placeholders are for feeding data in runtime\n",
    "ph_x = tf.placeholder(tf.float32, [n, 1])\n",
    "ph_t = tf.placeholder(tf.float32, [n, 1])\n",
    "\n",
    "deg = 3\n",
    "node_X = tf.pow(ph_x, tf.linspace(tf.to_float(deg),0,deg+1))\n",
    "\n",
    "# build a session\n",
    "sess = tf.Session()  \n",
    "\n",
    "# set an example data feed\n",
    "dataFeed = {ph_x:x} \n",
    "\n",
    "# run the session to evaluate the node weights\n",
    "X = sess.run(node_X, feed_dict=dataFeed)\n",
    "print(X[:n:10,])\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUHDEl-yBKft"
   },
   "source": [
    "## 3.3 Least-Squares Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1540321798797,
     "user": {
      "displayName": "Yipeng Hu",
      "photoUrl": "",
      "userId": "18139436242730223489"
     },
     "user_tz": -60
    },
    "id": "DYZu3MyaBKfw",
    "outputId": "3c7e3462-a1be-4d44-ca7c-70fc54d692b2"
   },
   "outputs": [],
   "source": [
    "# completing the computation graph with the least-square solution\n",
    "node_w = tf.matrix_solve_ls(node_X, ph_t)\n",
    "\n",
    "# run the session to evaluate the node weights\n",
    "sess = tf.Session()  \n",
    "dataFeed = {ph_x:x, ph_t:t_observed}  # feed data\n",
    "w_lstsq = sess.run(node_w, feed_dict=dataFeed)\n",
    "print(w_lstsq)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhy2ym8FBKf8"
   },
   "source": [
    "## 3.3 Stochastic Gradient Descend Method\n",
    "Instead of least-squares, weights can be optimised by minimising a loss function between the predicted- and observed target values, using SGD. This is for demo purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4030,
     "status": "ok",
     "timestamp": 1540321803016,
     "user": {
      "displayName": "Yipeng Hu",
      "photoUrl": "",
      "userId": "18139436242730223489"
     },
     "user_tz": -60
    },
    "id": "x2TDAsD-BKf_",
    "outputId": "01e04e4a-df38-41c5-9c56-db6a1109ed1d"
   },
   "outputs": [],
   "source": [
    "# build a new graph\n",
    "ph_1x = tf.placeholder(tf.float32, [1, 1])\n",
    "ph_1t = tf.placeholder(tf.float32, [1, 1])\n",
    "\n",
    "deg = 3\n",
    "node_X = tf.pow(ph_1x, tf.linspace(tf.to_float(deg),0,deg+1))\n",
    "\n",
    "# first declare variables that need optimisation\n",
    "var_w = tf.get_variable('weights', shape=[deg+1,1], \n",
    "                        initializer=tf.random_normal_initializer(0, 1e-3))\n",
    "\n",
    "# completing the computation graph with SGD\n",
    "node_1t = tf.matmul(node_X, var_w)\n",
    "# building a square loss\n",
    "loss = tf.reduce_mean(tf.square(node_1t-ph_1t))\n",
    "# buiding a train-op to minimise the loss\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "# launch a session\n",
    "sess = tf.Session()  \n",
    "sess.run(tf.global_variables_initializer())  # initialise all the variables\n",
    "\n",
    "# iteration to update variables with backprop gradients\n",
    "total_iter = int(1e4)\n",
    "indices_train = [i for i in range(n)]\n",
    "for step in range(total_iter):\n",
    "\n",
    "    idx = step % n\n",
    "    if idx == 0:  # shuffle every epoch\n",
    "        random.shuffle(indices_train)\n",
    "    \n",
    "    # single data point feed\n",
    "    singleDataFeed = {\n",
    "        ph_1x:x[indices_train[idx],np.newaxis], \n",
    "        ph_1t:t_observed[indices_train[idx],np.newaxis] }\n",
    "    \n",
    "    # update the variables\n",
    "    sess.run(train_op, feed_dict=singleDataFeed)\n",
    "    \n",
    "    # print training information\n",
    "    if (step % 200) == 0:\n",
    "        loss_train = sess.run(loss, feed_dict=singleDataFeed)\n",
    "        print('Step %d: Loss=%f' % (step, loss_train))\n",
    "    if (step % 2000) == 0:\n",
    "        w_sgd = sess.run(var_w)\n",
    "        print('Estimated weights:')\n",
    "        print(w_sgd)\n",
    "\n",
    "w_sgd = sess.run(var_w)\n",
    "print('Final weights at step %d:' % step)\n",
    "print(w_sgd)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxVSxLyeVdXb"
   },
   "source": [
    "## Questions\n",
    "- Try other optimisation hyperparameters, optimiser, learning rate, number of iterations.\n",
    "- Try add regularisers and different loss functions.\n",
    "- Would batch gradient descent or minibatch gradient descent improve the optimisation?\n",
    "- Would higher-degree models more prone to overfitting?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tutorials_3-CurveFitting-TensorFlow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
